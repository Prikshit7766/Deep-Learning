{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1685892861572,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"BAL3lWDi-5mq","outputId":"5c0b4c5b-1e03-49c9-bbc0-d6f1608d0f95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun  4 15:34:20 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   59C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26915,"status":"ok","timestamp":1685892888482,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"LeimRkaa_QEC","outputId":"09911c81-849b-4fa8-f425-6de836b057ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271250,"status":"ok","timestamp":1685893192685,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"nFI9y-36_bPc","outputId":"f21a5ca5-ef84-4e43-f8ad-d20bfec4516a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp310-cp310-linux_x86_64.whl size=44090 sha256=d9196f752fd85005d74f28d746efa4aa6df996fa17e2c1c2d6a242a021d49981\n","  Stored in directory: /root/.cache/pip/wheels/70/83/31/975b737609aba39a4099d471d5684141c1fdc3404f97e7f68a\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dask 2022.12.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\n","flax 0.6.9 requires PyYAML>=5.4.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pyyaml-5.1\n","torch:  2.0 ; cuda:  cu118\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-mh5b37jj\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-mh5b37jj\n","  Resolved https://github.com/facebookresearch/detectron2.git to commit dd2db71b0f8d855b71cac655186cbddca1bfda93\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (8.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.6)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n","Collecting yacs>=0.1.8 (from detectron2==0.6)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.8.10)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.65.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.12.2)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Collecting omegaconf>=2.1 (from detectron2==0.6)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting black (from detectron2==0.6)\n","  Downloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.3)\n","Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n","  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.3.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.40.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n","Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n","  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=7802707 sha256=f7b295d8b816e0c2d61db8f26e0cba0d14e5d1337d5483f5ab377c531cec01f5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-22o0_y07/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=2709a7e8b57b7147f889bfbe6845e6b2336c81417cbd9c98b0aa443c18196707\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=e00fb6888fb4d9d5c4e5afbbad18dfbec0d11d19673c21fa17858bf29095c8bd\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built detectron2 fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n","Successfully installed antlr4-python3-runtime-4.9.3 black-23.3.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.1 portalocker-2.7.0 yacs-0.1.8\n"]}],"source":["!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","# Install detectron2 that matches the above pytorch version\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n","!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"E6rY8xe9zjer","executionInfo":{"status":"ok","timestamp":1685893206268,"user_tz":-330,"elapsed":2509,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"}}},"outputs":[],"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1685893233236,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"5aD1RCDEhf9a","outputId":"b6b5b479-347e-4adf-b60c-95a6b07c1156"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cnn/image segmentaion/Detectron2\n"]}],"source":["%cd /content/drive/MyDrive/cnn/image segmentaion/Detectron2"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xO5Zj2vphrA0","executionInfo":{"status":"ok","timestamp":1685893468793,"user_tz":-330,"elapsed":880,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"}}},"outputs":[],"source":["from detectron2.data.datasets import register_coco_instances\n","register_coco_instances(\"sample\", {}, \"./data/trainval.json\", \"./data/images\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":523,"status":"ok","timestamp":1685893470950,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"ueyA4Wy_hy8t","outputId":"ae58f00c-c1a3-45fe-9653-42688563ff3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING [06/04 15:44:30 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[06/04 15:44:30 d2.data.datasets.coco]: Loaded 51 images in COCO format from ./data/trainval.json\n"]}],"source":["sample_metadata = MetadataCatalog.get(\"sample\")\n","dataset_dicts = DatasetCatalog.get(\"sample\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bgct1g8qWb7VanQktptoUUv14ftFIgTk"},"executionInfo":{"elapsed":11754,"status":"ok","timestamp":1685893482703,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"pfvft7q4n8Ny","outputId":"dbae1e17-dcd9-4b85-a404-2912c82992f0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","\n","for d in random.sample(dataset_dicts, 4):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=sample_metadata, scale=0.5)\n","    vis = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(vis.get_image()[:, :, ::-1])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163425,"status":"ok","timestamp":1685894157990,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"VwYtL5qa0qib","outputId":"4673e16c-bd54-461c-8647-dbd225f1c9bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["[06/04 15:53:15 d2.engine.defaults]: Model:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=56, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","WARNING [06/04 15:53:15 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[06/04 15:53:15 d2.data.datasets.coco]: Loaded 51 images in COCO format from ./data/trainval.json\n","[06/04 15:53:15 d2.data.build]: Removed 0 images with no usable annotations. 51 images left.\n","[06/04 15:53:15 d2.data.build]: Distribution of instances among all 14 categories:\n","|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|   Apple    | 7            |    Car     | 29           |   Cherry   | 18           |\n","|   Chilly   | 2            |    Cow     | 4            |    Dog     | 10           |\n","|   Grapes   | 25           |   Helmet   | 12           |   Koala    | 5            |\n","|    Mask    | 7            |   Person   | 24           |   Person   | 0            |\n","|   Person   | 0            | Strawberry | 14           |            |              |\n","|   total    | 157          |            |              |            |              |\n","[06/04 15:53:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","[06/04 15:53:15 d2.data.build]: Using training sampler TrainingSampler\n","[06/04 15:53:15 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[06/04 15:53:15 d2.data.common]: Serializing 51 elements to byte tensors and concatenating them all ...\n","[06/04 15:53:15 d2.data.common]: Serialized dataset takes 0.13 MiB\n","WARNING [06/04 15:53:15 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","[06/04 15:53:15 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["model_final_f10217.pkl: 178MB [00:00, 183MB/s]                           \n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (56, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (56,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["[06/04 15:53:17 d2.engine.train_loop]: Starting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[06/04 15:53:32 d2.utils.events]:  eta: 0:02:38  iter: 19  total_loss: 3.704  loss_cls: 2.458  loss_box_reg: 0.5708  loss_mask: 0.6916  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.009581    time: 0.5678  last_time: 0.6381  data_time: 0.1442  last_data_time: 0.1075   lr: 0.00016068  max_mem: 2668M\n","[06/04 15:53:45 d2.utils.events]:  eta: 0:02:13  iter: 39  total_loss: 2.14  loss_cls: 0.878  loss_box_reg: 0.641  loss_mask: 0.6379  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01273    time: 0.5338  last_time: 0.6453  data_time: 0.0204  last_data_time: 0.0583   lr: 0.00032718  max_mem: 2668M\n","[06/04 15:53:54 d2.utils.events]:  eta: 0:01:57  iter: 59  total_loss: 1.866  loss_cls: 0.7064  loss_box_reg: 0.5997  loss_mask: 0.5685  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.008033    time: 0.5099  last_time: 0.5184  data_time: 0.0245  last_data_time: 0.0061   lr: 0.00049367  max_mem: 2668M\n","[06/04 15:54:05 d2.utils.events]:  eta: 0:01:48  iter: 79  total_loss: 1.752  loss_cls: 0.6725  loss_box_reg: 0.6794  loss_mask: 0.4328  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.01022    time: 0.5136  last_time: 0.4255  data_time: 0.0459  last_data_time: 0.0075   lr: 0.00066017  max_mem: 2675M\n","[06/04 15:54:14 d2.utils.events]:  eta: 0:01:38  iter: 99  total_loss: 1.489  loss_cls: 0.479  loss_box_reg: 0.6747  loss_mask: 0.3042  loss_rpn_cls: 0.008255  loss_rpn_loc: 0.01167    time: 0.5072  last_time: 0.6094  data_time: 0.0152  last_data_time: 0.0246   lr: 0.00082668  max_mem: 2675M\n","[06/04 15:54:24 d2.utils.events]:  eta: 0:01:28  iter: 119  total_loss: 1.329  loss_cls: 0.3753  loss_box_reg: 0.6204  loss_mask: 0.2214  loss_rpn_cls: 0.003205  loss_rpn_loc: 0.01228    time: 0.5055  last_time: 0.4778  data_time: 0.0145  last_data_time: 0.0054   lr: 0.00099318  max_mem: 2675M\n","[06/04 15:54:34 d2.utils.events]:  eta: 0:01:19  iter: 139  total_loss: 0.9978  loss_cls: 0.3014  loss_box_reg: 0.5713  loss_mask: 0.1723  loss_rpn_cls: 0.001505  loss_rpn_loc: 0.0123    time: 0.5046  last_time: 0.5051  data_time: 0.0115  last_data_time: 0.0049   lr: 0.0011597  max_mem: 2675M\n","[06/04 15:54:44 d2.utils.events]:  eta: 0:01:09  iter: 159  total_loss: 0.9606  loss_cls: 0.1801  loss_box_reg: 0.5196  loss_mask: 0.1521  loss_rpn_cls: 0.002032  loss_rpn_loc: 0.01493    time: 0.5045  last_time: 0.4178  data_time: 0.0207  last_data_time: 0.0298   lr: 0.0013262  max_mem: 2675M\n","[06/04 15:54:54 d2.utils.events]:  eta: 0:00:59  iter: 179  total_loss: 0.8681  loss_cls: 0.2266  loss_box_reg: 0.4119  loss_mask: 0.1161  loss_rpn_cls: 0.0009723  loss_rpn_loc: 0.01018    time: 0.5030  last_time: 0.4689  data_time: 0.0132  last_data_time: 0.0083   lr: 0.0014927  max_mem: 2675M\n","[06/04 15:55:05 d2.utils.events]:  eta: 0:00:49  iter: 199  total_loss: 0.6543  loss_cls: 0.1531  loss_box_reg: 0.3408  loss_mask: 0.1157  loss_rpn_cls: 0.003573  loss_rpn_loc: 0.01216    time: 0.5050  last_time: 0.5872  data_time: 0.0216  last_data_time: 0.0048   lr: 0.0016592  max_mem: 2675M\n","[06/04 15:55:15 d2.utils.events]:  eta: 0:00:39  iter: 219  total_loss: 0.74  loss_cls: 0.2279  loss_box_reg: 0.3435  loss_mask: 0.1159  loss_rpn_cls: 0.001765  loss_rpn_loc: 0.01062    time: 0.5063  last_time: 0.4440  data_time: 0.0199  last_data_time: 0.0078   lr: 0.0018257  max_mem: 2675M\n","[06/04 15:55:25 d2.utils.events]:  eta: 0:00:30  iter: 239  total_loss: 0.534  loss_cls: 0.1255  loss_box_reg: 0.3085  loss_mask: 0.1262  loss_rpn_cls: 0.0004666  loss_rpn_loc: 0.01082    time: 0.5060  last_time: 0.5683  data_time: 0.0095  last_data_time: 0.0102   lr: 0.0019922  max_mem: 2675M\n","[06/04 15:55:35 d2.utils.events]:  eta: 0:00:20  iter: 259  total_loss: 0.6226  loss_cls: 0.1661  loss_box_reg: 0.3169  loss_mask: 0.1093  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.01002    time: 0.5055  last_time: 0.4255  data_time: 0.0183  last_data_time: 0.0041   lr: 0.0021587  max_mem: 2675M\n","[06/04 15:55:46 d2.utils.events]:  eta: 0:00:10  iter: 279  total_loss: 0.5808  loss_cls: 0.1177  loss_box_reg: 0.3073  loss_mask: 0.1084  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.00924    time: 0.5067  last_time: 0.5408  data_time: 0.0160  last_data_time: 0.0044   lr: 0.0023252  max_mem: 2675M\n","[06/04 15:55:57 d2.utils.events]:  eta: 0:00:00  iter: 299  total_loss: 0.5174  loss_cls: 0.1296  loss_box_reg: 0.2807  loss_mask: 0.09674  loss_rpn_cls: 0.001097  loss_rpn_loc: 0.008717    time: 0.5059  last_time: 0.6414  data_time: 0.0086  last_data_time: 0.0060   lr: 0.0024917  max_mem: 2675M\n","[06/04 15:55:57 d2.engine.hooks]: Overall training speed: 298 iterations in 0:02:30 (0.5059 s / it)\n","[06/04 15:55:57 d2.engine.hooks]: Total training time: 0:02:35 (0:00:04 on hooks)\n"]}],"source":["from detectron2.engine import DefaultTrainer\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"sample\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 14  # (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1746,"status":"ok","timestamp":1685894159733,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"05BACyruqh6S","outputId":"593a9dd5-b3da-4c7c-bac5-a848f4dfe9cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[06/04 15:55:58 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"]}],"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"sample\", )\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZI_Fjvxbm1wxORfJBi4Hq430CNmFhWKj"},"executionInfo":{"elapsed":10090,"status":"ok","timestamp":1685894184493,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"z5WadiH8qm47","outputId":"627f9ffd-0ded-41ed-c1e7-34e128dd290f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from detectron2.utils.visualizer import ColorMode\n","\n","for d in random.sample(dataset_dicts, 4):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=sample_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"2KxsS7M10Egt"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3173,"status":"ok","timestamp":1685894188541,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"QFpuZbRWz4tc","outputId":"a3833d61-f0f4-46d0-f384-cebd6c10350f"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING [06/04 15:56:18 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[06/04 15:56:18 d2.data.datasets.coco]: Loaded 51 images in COCO format from ./data/trainval.json\n","[06/04 15:56:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[06/04 15:56:18 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[06/04 15:56:18 d2.data.common]: Serializing 51 elements to byte tensors and concatenating them all ...\n","[06/04 15:56:18 d2.data.common]: Serialized dataset takes 0.13 MiB\n","[06/04 15:56:18 d2.evaluation.evaluator]: Start inference on 51 batches\n","[06/04 15:56:20 d2.evaluation.evaluator]: Inference done 11/51. Dataloading: 0.0015 s/iter. Inference: 0.1125 s/iter. Eval: 0.0027 s/iter. Total: 0.1168 s/iter. ETA=0:00:04\n","[06/04 15:56:25 d2.evaluation.evaluator]: Inference done 35/51. Dataloading: 0.0218 s/iter. Inference: 0.1526 s/iter. Eval: 0.0171 s/iter. Total: 0.1916 s/iter. ETA=0:00:03\n","[06/04 15:56:28 d2.evaluation.evaluator]: Total inference time: 0:00:08.639658 (0.187819 s / iter per device, on 1 devices)\n","[06/04 15:56:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:06 (0.147419 s / iter per device, on 1 devices)\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.603\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.563\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.429\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 49.347 | 72.903 | 60.322 | 36.208 | 39.647 | 56.299 |\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n","| category   | AP     | category   | AP     | category   | AP     |\n","|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n","| Apple      | 83.486 | Car        | 62.241 | Cherry     | 48.185 |\n","| Chilly     | 0.000  | Cow        | 56.898 | Dog        | 81.623 |\n","| Grapes     | 43.725 | Helmet     | 9.639  | Koala      | 66.865 |\n","| Mask       | 30.627 | Person     | 62.406 | Person     | nan    |\n","| Person     | nan    | Strawberry | 46.464 |            |        |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[06/04 15:56:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.659\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.429\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.384\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.678\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.482\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n","|:------:|:------:|:------:|:------:|:------:|:------:|\n","| 60.239 | 74.764 | 65.929 | 42.901 | 53.207 | 68.717 |\n","[06/04 15:56:28 d2.evaluation.coco_evaluation]: Per-category segm AP: \n","| category   | AP     | category   | AP     | category   | AP     |\n","|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n","| Apple      | 92.653 | Car        | 79.075 | Cherry     | 53.899 |\n","| Chilly     | 0.000  | Cow        | 64.422 | Dog        | 90.000 |\n","| Grapes     | 57.428 | Helmet     | 40.399 | Koala      | 72.178 |\n","| Mask       | 43.762 | Person     | 71.212 | Person     | nan    |\n","| Person     | nan    | Strawberry | 57.835 |            |        |\n","OrderedDict([('bbox', {'AP': 49.34654369829312, 'AP50': 72.90262735206929, 'AP75': 60.3219635478837, 'APs': 36.20785710149962, 'APm': 39.64733674937595, 'APl': 56.29927685315115, 'AP-Apple': 83.48597359735975, 'AP-Car': 62.24082140718411, 'AP-Cherry': 48.184911762866236, 'AP-Chilly': 0.0, 'AP-Cow': 56.89768976897689, 'AP-Dog': 81.62329090051863, 'AP-Grapes': 43.72487707954469, 'AP-Helmet': 9.63918868594934, 'AP-Koala': 66.86468646864687, 'AP-Mask': 30.627062706270625, 'AP-Person': nan, 'AP-Strawberry': 46.464246424642475}), ('segm', {'AP': 60.23860939300246, 'AP50': 74.76366952512717, 'AP75': 65.92935661461966, 'APs': 42.90117748068128, 'APm': 53.20745687639904, 'APl': 68.7169980643626, 'AP-Apple': 92.6526402640264, 'AP-Car': 79.07464729989483, 'AP-Cherry': 53.89873306630288, 'AP-Chilly': 0.0, 'AP-Cow': 64.42244224422441, 'AP-Dog': 90.0, 'AP-Grapes': 57.42818975775129, 'AP-Helmet': 40.39929769374453, 'AP-Koala': 72.17821782178217, 'AP-Mask': 43.76237623762376, 'AP-Person': nan, 'AP-Strawberry': 57.83498349834984})])\n"]}],"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"sample\", output_dir= \"./output\")\n","val_loader = build_detection_test_loader(cfg, \"sample\")\n","print(inference_on_dataset(predictor.model, val_loader, evaluator))"]},{"cell_type":"markdown","metadata":{"id":"t0Wd1VYj0I2j"},"source":["## Getting the custom config file"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685894188542,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"},"user_tz":-330},"id":"J9mWjL8zz4vm","outputId":"5ebf2c35-0085-4fd2-9211-bf552bfb0986"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/cnn/image segmentaion/Detectron2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["pwd"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Oy3KOBGC2JvH","executionInfo":{"status":"ok","timestamp":1685894188542,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"}}},"outputs":[],"source":["f = open('config.yml', 'w')\n","f.write(cfg.dump())\n","f.close()"]},{"cell_type":"code","source":[],"metadata":{"id":"tUlUyfl3H7Bp","executionInfo":{"status":"ok","timestamp":1685894188543,"user_tz":-330,"elapsed":6,"user":{"displayName":"Prikshit sharma","userId":"07819241395213139913"}}},"execution_count":14,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}